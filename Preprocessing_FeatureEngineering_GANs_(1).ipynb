{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maryam-youssef/Fraud-Detection/blob/main/Preprocessing_FeatureEngineering_GANs_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTL58nQ1pChx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFuCDukZpCh1",
        "outputId": "0c14d5c8-ea37-4fac-b7b3-cc3f6fd03bfe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:1: SyntaxWarning: invalid escape sequence '\\S'\n",
            "<>:1: SyntaxWarning: invalid escape sequence '\\S'\n",
            "C:\\Users\\mario\\AppData\\Local\\Temp\\ipykernel_16128\\3510858160.py:1: SyntaxWarning: invalid escape sequence '\\S'\n",
            "  df = pd.read_csv('archive\\Synthetic_Financial_datasets_log.csv')\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('archive\\Synthetic_Financial_datasets_log.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WMoGNjjIpCh3",
        "outputId": "f3f67500-d89f-42f4-a26e-b133de0efd0c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>step</th>\n",
              "      <th>type</th>\n",
              "      <th>amount</th>\n",
              "      <th>nameOrig</th>\n",
              "      <th>oldbalanceOrg</th>\n",
              "      <th>newbalanceOrig</th>\n",
              "      <th>nameDest</th>\n",
              "      <th>oldbalanceDest</th>\n",
              "      <th>newbalanceDest</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>isFlaggedFraud</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>PAYMENT</td>\n",
              "      <td>9839.64</td>\n",
              "      <td>C1231006815</td>\n",
              "      <td>170136.0</td>\n",
              "      <td>160296.36</td>\n",
              "      <td>M1979787155</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>PAYMENT</td>\n",
              "      <td>1864.28</td>\n",
              "      <td>C1666544295</td>\n",
              "      <td>21249.0</td>\n",
              "      <td>19384.72</td>\n",
              "      <td>M2044282225</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>TRANSFER</td>\n",
              "      <td>181.00</td>\n",
              "      <td>C1305486145</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>C553264065</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>CASH_OUT</td>\n",
              "      <td>181.00</td>\n",
              "      <td>C840083671</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>C38997010</td>\n",
              "      <td>21182.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>PAYMENT</td>\n",
              "      <td>11668.14</td>\n",
              "      <td>C2048537720</td>\n",
              "      <td>41554.0</td>\n",
              "      <td>29885.86</td>\n",
              "      <td>M1230701703</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
              "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
              "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
              "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
              "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
              "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
              "\n",
              "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
              "0  M1979787155             0.0             0.0        0               0  \n",
              "1  M2044282225             0.0             0.0        0               0  \n",
              "2   C553264065             0.0             0.0        1               0  \n",
              "3    C38997010         21182.0             0.0        1               0  \n",
              "4  M1230701703             0.0             0.0        0               0  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcbtOObnpCh3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Label Encoding for the 'type' column\n",
        "label_encoder = LabelEncoder()\n",
        "df['type'] = label_encoder.fit_transform(df['type'])\n",
        "\n",
        "# Feature Engineering\n",
        "\n",
        "# Drastic change in balance after the transaction\n",
        "df['balance_change_orig'] = df['oldbalanceOrg'] - df['newbalanceOrig']\n",
        "\n",
        "# Flagging transactions where the sender's balance is drained\n",
        "df['drained_orig_balance'] = np.where((df['newbalanceOrig'] == 0) & (df['amount'] > 0), 1, 0)\n",
        "\n",
        "# Flagging transactions where the destination had zero balance before the transaction\n",
        "df['zero_balance_dest'] = np.where(df['oldbalanceDest'] == 0, 1, 0)\n",
        "df['zero_balance_orig'] = np.where(df['oldbalanceOrg'] == 0, 1, 0)\n",
        "\n",
        "# Dropping low-correlation columns\n",
        "df.drop(columns=['step'], inplace=True)\n",
        "df.drop(columns=['nameOrig'], inplace=True)\n",
        "df.drop(columns=['nameDest'], inplace=True)\n",
        "df.drop(columns=['newbalanceDest'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sR9nEXsOuqx8",
        "outputId": "60ab1383-f9d3-4891-f8fd-0be7c9aaec34"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>amount</th>\n",
              "      <th>oldbalanceOrg</th>\n",
              "      <th>newbalanceOrig</th>\n",
              "      <th>oldbalanceDest</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>isFlaggedFraud</th>\n",
              "      <th>balance_change_orig</th>\n",
              "      <th>drained_orig_balance</th>\n",
              "      <th>zero_balance_dest</th>\n",
              "      <th>zero_balance_orig</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>9839.64</td>\n",
              "      <td>170136.0</td>\n",
              "      <td>160296.36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9839.64</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>1864.28</td>\n",
              "      <td>21249.0</td>\n",
              "      <td>19384.72</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1864.28</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>181.00</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>181.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>181.00</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>21182.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>181.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>11668.14</td>\n",
              "      <td>41554.0</td>\n",
              "      <td>29885.86</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11668.14</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type    amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  isFraud  \\\n",
              "0     3   9839.64       170136.0       160296.36             0.0        0   \n",
              "1     3   1864.28        21249.0        19384.72             0.0        0   \n",
              "2     4    181.00          181.0            0.00             0.0        1   \n",
              "3     1    181.00          181.0            0.00         21182.0        1   \n",
              "4     3  11668.14        41554.0        29885.86             0.0        0   \n",
              "\n",
              "   isFlaggedFraud  balance_change_orig  drained_orig_balance  \\\n",
              "0               0              9839.64                     0   \n",
              "1               0              1864.28                     0   \n",
              "2               0               181.00                     1   \n",
              "3               0               181.00                     1   \n",
              "4               0             11668.14                     0   \n",
              "\n",
              "   zero_balance_dest  zero_balance_orig  \n",
              "0                  1                  0  \n",
              "1                  1                  0  \n",
              "2                  1                  0  \n",
              "3                  0                  0  \n",
              "4                  1                  0  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "kgGnJ_IspCh4",
        "outputId": "8cfe2c30-1547-444c-def7-e4767fdad19c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "type                    0.020833\n",
              "amount                  0.076688\n",
              "oldbalanceOrg           0.010154\n",
              "newbalanceOrig         -0.008148\n",
              "oldbalanceDest         -0.005885\n",
              "isFraud                 1.000000\n",
              "isFlaggedFraud          0.044109\n",
              "balance_change_orig     0.362472\n",
              "drained_orig_balance    0.029843\n",
              "zero_balance_dest       0.016471\n",
              "zero_balance_orig      -0.024874\n",
              "dtype: float64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.corrwith(df[\"isFraud\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QqFpvW_pCh4",
        "outputId": "01b11cda-ca26-495e-bc3e-fe8e2a840504"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend \u001b[38;5;28;01mas\u001b[39;00m K\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Prepare dataset\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124misFraud\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     13\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124misFraud\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Apply Standard Scaling\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import Precision, Recall\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Prepare dataset\n",
        "X = df.drop('isFraud', axis=1)\n",
        "y = df['isFraud']\n",
        "\n",
        "# Apply Standard Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Splitting the data using stratified train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Combining the features and labels for the training set\n",
        "train_df = pd.DataFrame(X_train, columns=X.columns)\n",
        "train_df['isFraud'] = y_train.values\n",
        "\n",
        "# Separate isFraud and non-isFraud data\n",
        "isFraud_data = train_df[train_df['isFraud'] == 1].drop('isFraud', axis=1).values\n",
        "non_isFraud_data = train_df[train_df['isFraud'] == 0].drop('isFraud', axis=1).values\n",
        "\n",
        "# Calculate the number of synthetic isFraud samples needed\n",
        "num_real_isFraud = len(isFraud_data)\n",
        "#num_synthetic_samples = len(non_isFraud_data) - num_real_isFraud\n",
        "num_synthetic_samples = 1000000\n",
        "print(\"# of non-isFraud: \", len(non_isFraud_data))\n",
        "print(\"# of Real isFraud: \", num_real_isFraud)\n",
        "print(\"# of Synthetic isFraud required: \", num_synthetic_samples)\n",
        "\n",
        "# Define the generator network\n",
        "def build_generator(latent_dim, output_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_shape=(latent_dim,)))\n",
        "    model.add(Dense(128, activation='sigmoid'))\n",
        "    model.add(Dense(output_dim, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# Define the discriminator network\n",
        "def build_discriminator(input_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, activation='sigmoid', input_dim=input_dim))\n",
        "    model.add(Dense(128, activation='sigmoid'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# Custom loss function for the generator\n",
        "def generator_loss_log_d(y_true, y_pred):\n",
        "    return -K.mean(K.log(y_pred + K.epsilon()))\n",
        "\n",
        "\n",
        "# Dimensionality of the input noise for the generator\n",
        "latent_dim = 32\n",
        "\n",
        "# Build the generator and discriminator\n",
        "generator = build_generator(latent_dim, isFraud_data.shape[1])\n",
        "discriminator = build_discriminator(isFraud_data.shape[1])\n",
        "\n",
        "# Compile the discriminator with cross-entropy loss and precision/recall metrics\n",
        "discriminator.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy', metrics=[Precision(), Recall()])\n",
        "\n",
        "# Build and compile the GANs main optimization loop\n",
        "def build_gan(generator, discriminator):\n",
        "    discriminator.trainable = False  # Freeze discriminator when training the generator\n",
        "    model = Sequential()\n",
        "    model.add(generator)\n",
        "    model.add(discriminator)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss=generator_loss_log_d)\n",
        "    return model\n",
        "\n",
        "# Compile the GAN model\n",
        "gan = build_gan(generator, discriminator)\n",
        "\n",
        "# Set training parameters\n",
        "epochs = 1000\n",
        "batch_size = 32\n",
        "\n",
        "# Training loop for GANs\n",
        "for epoch in range(epochs):\n",
        "    # Train the discriminator\n",
        "    discriminator.trainable = True\n",
        "    generator.trainable = False\n",
        "\n",
        "    # Random sampling from real isFraud data\n",
        "    real_isFraud_samples = isFraud_data[np.random.randint(0, num_real_isFraud, batch_size)]\n",
        "\n",
        "    # Generate fake isFraud samples using the generator\n",
        "    noise = np.random.normal(0, 1, size=(batch_size, latent_dim))\n",
        "    fake_isFraud_samples = generator.predict(noise)\n",
        "\n",
        "    # Create labels for real and fake isFraud samples\n",
        "    real_labels = np.ones((batch_size, 1))\n",
        "    fake_labels = np.zeros((batch_size, 1))\n",
        "\n",
        "    # Train the discriminator on real and fake isFraud samples\n",
        "    d_loss_real = discriminator.train_on_batch(real_isFraud_samples, real_labels)\n",
        "    d_loss_fake = discriminator.train_on_batch(fake_isFraud_samples, fake_labels)\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    # Train the generator\n",
        "    discriminator.trainable = False\n",
        "    generator.trainable = True\n",
        "\n",
        "    # Generate noise and valid labels for generator training\n",
        "    noise = np.random.normal(0, 1, size=(batch_size, latent_dim))\n",
        "    valid_labels = np.ones((batch_size, 1))\n",
        "\n",
        "    # Train the generator to fool the discriminator\n",
        "    g_loss = gan.train_on_batch(noise, valid_labels)\n",
        "\n",
        "    # Print progress every 100 epochs\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch: {epoch} - D Loss: {d_loss} - G Loss: {g_loss}\")\n",
        "\n",
        "# Generate synthetic isFraud data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0KQOl9JMjh7",
        "outputId": "e7c18779-160b-4f51-90de-9b587dd9f5c8"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'num_synthetic_samples' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m noise \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39m(\u001b[43mnum_synthetic_samples\u001b[49m, latent_dim))\n\u001b[0;32m      5\u001b[0m synthetic_isFraud_data \u001b[38;5;241m=\u001b[39m generator\u001b[38;5;241m.\u001b[39mpredict(noise)\n\u001b[0;32m      6\u001b[0m synthetic_isFraud_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(synthetic_isFraud_data, columns\u001b[38;5;241m=\u001b[39mcolumn_names)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'num_synthetic_samples' is not defined"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "noise = np.random.normal(0, 1, size=(num_synthetic_samples, latent_dim))\n",
        "synthetic_isFraud_data = generator.predict(noise)\n",
        "\n",
        "# Convert synthetic isFraud data into a DataFrame\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Convert NumPy array\n",
        "column_names = ['type','amount','oldbalanceOrg','newbalanceOrig','oldbalanceDest','isFlaggedFraud','balance_change_orig','drained_orig_balance','zero_balance_dest','zero_balance_orig']\n",
        "\n",
        "synthetic_isFraud_df = pd.DataFrame(synthetic_isFraud_data, columns=column_names)\n",
        "# Combine the original isFraud data with the synthetic isFraud data\n",
        "balanced_train_df = pd.concat([train_df[train_df['isFraud'] == 0], synthetic_isFraud_df])\n",
        "\n",
        "\n",
        "# Convert synthetic isFraud data into a DataFrame\n",
        "# Assuming column names based on features used\n",
        "column_names = ['type', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest',\n",
        "                'isFlaggedFraud', 'balance_change_orig', 'drained_orig_balance',\n",
        "                'zero_balance_dest', 'zero_balance_orig']\n",
        "\n",
        "synthetic_isFraud_df = pd.DataFrame(synthetic_isFraud_data, columns=column_names)\n",
        "\n",
        "# Add the 'isFraud' label to the synthetic data\n",
        "synthetic_isFraud_df['isFraud'] = 1\n",
        "\n",
        "# Combine the original non-isFraud data with the synthetic isFraud data\n",
        "balanced_train_df = pd.concat([train_df[train_df['isFraud'] == 0], synthetic_isFraud_df])\n",
        "\n",
        "# Shuffle the balanced training dataset\n",
        "balanced_train_df = balanced_train_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Save the combined DataFrame for later use\n",
        "balanced_train_df.to_csv('balanced_train_data.csv', index=False)\n",
        "\n",
        "print(\"Balanced training data saved successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMNe6TVYMjh8"
      },
      "outputs": [],
      "source": [
        "balanced_train_df.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVOoFsMoMjh8",
        "outputId": "de6591d9-8e98-4c6d-fe14-4218d01688bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Balanced dataset saved to balanced_train_data.csv\n"
          ]
        }
      ],
      "source": [
        "# Save the balanced dataset to a CSV file\n",
        "output_file_path = 'balanced_train_data.csv'  # Specify your desired file name and path\n",
        "balanced_train_df.to_csv(output_file_path, index=False)  # Save DataFrame to CSV without row indices\n",
        "print(f\"Balanced dataset saved to {output_file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbguV1OnMjh9",
        "outputId": "7ca0c5ae-1b34-443d-9e2f-e19ffca61168"
      },
      "outputs": [
        {
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: out of memory",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[25], line 24\u001b[0m\n\u001b[0;32m      7\u001b[0m dtype \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamount\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzero_balance_orig\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     21\u001b[0m }\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Read the CSV in chunks\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mE:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mNTI Graduation\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mbalanced_train_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Concatenate all chunks into a single DataFrame\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\mario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1843\u001b[0m, in \u001b[0;36mTextFileReader.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1841\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   1842\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1843\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1844\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m   1845\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
            "File \u001b[1;32mc:\\Users\\mario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1985\u001b[0m, in \u001b[0;36mTextFileReader.get_chunk\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m   1983\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m   1984\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrows \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow)\n\u001b[1;32m-> 1985\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\mario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
            "File \u001b[1;32mc:\\Users\\mario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
            "File \u001b[1;32mparsers.pyx:850\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: out of memory"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Initialize an empty list to hold the chunks\n",
        "df_list = []\n",
        "\n",
        "# Define the column data types to optimize memory usage\n",
        "dtype = {\n",
        "    'type': 'category',\n",
        "    'amount': 'float32',\n",
        "    'oldbalanceOrg': 'float32',\n",
        "    'newbalanceOrig': 'float32',\n",
        "    'nameOrig': 'object',\n",
        "    'oldbalanceDest': 'float32',\n",
        "    'newbalanceDest': 'float32',\n",
        "    'isFraud': 'int8',\n",
        "    'isFlaggedFraud': 'int8',\n",
        "    'balance_change_orig': 'float32',\n",
        "    'drained_orig_balance': 'float32',\n",
        "    'zero_balance_dest': 'int8',\n",
        "    'zero_balance_orig': 'int8'\n",
        "}\n",
        "\n",
        "# Read the CSV in chunks\n",
        "for chunk in pd.read_csv('E:\\\\NTI Graduation\\\\balanced_train_data.csv', chunksize=100000, dtype=dtype):\n",
        "    df_list.append(chunk)\n",
        "\n",
        "# Concatenate all chunks into a single DataFrame\n",
        "df_final = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "# Proceed with further processing\n",
        "X = df_final.drop('isFraud', axis=1)\n",
        "y = df_final['isFraud']\n",
        "\n",
        "# Example: Display the first few rows of the DataFrame\n",
        "print(df_final.head())\n",
        "\n",
        "# Continue with your model training and analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4sdxUroMjh9",
        "outputId": "462d57b1-6904-4e1f-d8bb-071748b8f6ad"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>amount</th>\n",
              "      <th>oldbalanceOrg</th>\n",
              "      <th>newbalanceOrig</th>\n",
              "      <th>oldbalanceDest</th>\n",
              "      <th>isFlaggedFraud</th>\n",
              "      <th>balance_change_orig</th>\n",
              "      <th>drained_orig_balance</th>\n",
              "      <th>zero_balance_dest</th>\n",
              "      <th>zero_balance_orig</th>\n",
              "      <th>isFraud</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.269631</td>\n",
              "      <td>0.342006</td>\n",
              "      <td>1.328035</td>\n",
              "      <td>1.436652</td>\n",
              "      <td>-0.174944</td>\n",
              "      <td>-0.001586</td>\n",
              "      <td>-2.490087</td>\n",
              "      <td>-1.145033</td>\n",
              "      <td>-0.859803</td>\n",
              "      <td>-0.702505</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.269631</td>\n",
              "      <td>0.053981</td>\n",
              "      <td>-0.207478</td>\n",
              "      <td>-0.139539</td>\n",
              "      <td>-0.086687</td>\n",
              "      <td>-0.001586</td>\n",
              "      <td>-1.304037</td>\n",
              "      <td>-1.145033</td>\n",
              "      <td>-0.859803</td>\n",
              "      <td>-0.702505</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.952399</td>\n",
              "      <td>-0.264788</td>\n",
              "      <td>-0.287458</td>\n",
              "      <td>-0.292442</td>\n",
              "      <td>-0.323814</td>\n",
              "      <td>-0.001586</td>\n",
              "      <td>0.169558</td>\n",
              "      <td>0.873337</td>\n",
              "      <td>1.163057</td>\n",
              "      <td>-0.702505</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.528954</td>\n",
              "      <td>0.575888</td>\n",
              "      <td>-0.226320</td>\n",
              "      <td>-0.292442</td>\n",
              "      <td>-0.296702</td>\n",
              "      <td>-0.001586</td>\n",
              "      <td>1.373718</td>\n",
              "      <td>0.873337</td>\n",
              "      <td>-0.859803</td>\n",
              "      <td>-0.702505</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.693076</td>\n",
              "      <td>0.043398</td>\n",
              "      <td>-0.288716</td>\n",
              "      <td>-0.292442</td>\n",
              "      <td>0.303248</td>\n",
              "      <td>-0.001586</td>\n",
              "      <td>0.144777</td>\n",
              "      <td>0.873337</td>\n",
              "      <td>-0.859803</td>\n",
              "      <td>1.423478</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       type    amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
              "0 -1.269631  0.342006       1.328035        1.436652       -0.174944   \n",
              "1 -1.269631  0.053981      -0.207478       -0.139539       -0.086687   \n",
              "2  0.952399 -0.264788      -0.287458       -0.292442       -0.323814   \n",
              "3 -0.528954  0.575888      -0.226320       -0.292442       -0.296702   \n",
              "4  1.693076  0.043398      -0.288716       -0.292442        0.303248   \n",
              "\n",
              "   isFlaggedFraud  balance_change_orig  drained_orig_balance  \\\n",
              "0       -0.001586            -2.490087             -1.145033   \n",
              "1       -0.001586            -1.304037             -1.145033   \n",
              "2       -0.001586             0.169558              0.873337   \n",
              "3       -0.001586             1.373718              0.873337   \n",
              "4       -0.001586             0.144777              0.873337   \n",
              "\n",
              "   zero_balance_dest  zero_balance_orig  isFraud  \n",
              "0          -0.859803          -0.702505      0.0  \n",
              "1          -0.859803          -0.702505      0.0  \n",
              "2           1.163057          -0.702505      0.0  \n",
              "3          -0.859803          -0.702505      0.0  \n",
              "4          -0.859803           1.423478      0.0  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df_final = pd.read_csv(r'E:\\NTI Graduation\\balanced_train_data.csv')\n",
        "df_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-4jwnJ1Mjh-",
        "outputId": "3f1d5498-b9e3-45b2-8383-b6ce21cbcda7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaN values found in features or target variable, removing those rows...\n",
            "\n",
            "Class distribution in the training set:\n",
            " isFraud\n",
            "0.0    4066888\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Build and train the Logistic Regression model\u001b[39;00m\n\u001b[0;32m     30\u001b[0m logistic_model \u001b[38;5;241m=\u001b[39m LogisticRegression(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m \u001b[43mlogistic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m     34\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m logistic_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
            "File \u001b[1;32mc:\\Users\\mario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\mario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1301\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1299\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1301\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1305\u001b[0m     )\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1308\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Prepare dataset\n",
        "#df_final = pd.read_csv(r'E:\\NTI Graduation\\balanced_train_data.csv')\n",
        "X = df_final.drop('isFraud', axis=1)\n",
        "y = df_final['isFraud']\n",
        "\n",
        "# Apply Standard Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Splitting the data using stratified train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check for NaN values and remove them\n",
        "if np.isnan(X_train).any() or np.isnan(y_train).any():\n",
        "    print(\"NaN values found in features or target variable, removing those rows...\")\n",
        "    X_train = X_train[~np.isnan(y_train)]\n",
        "    y_train = y_train[~np.isnan(y_train)]\n",
        "\n",
        "# Check class distribution\n",
        "print(\"\\nClass distribution in the training set:\\n\", pd.Series(y_train).value_counts())\n",
        "\n",
        "# Build and train the Logistic Regression model\n",
        "logistic_model = LogisticRegression(class_weight='balanced', random_state=42)\n",
        "logistic_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = logistic_model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Validation Accuracy:\", logistic_model.score(X_test, y_test))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Feature importance (coefficients)\n",
        "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': logistic_model.coef_[0]})\n",
        "print(\"\\nFeature Importance:\\n\", feature_importance_df.sort_values(by='Importance', ascending=False))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}